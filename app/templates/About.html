<html lang="en">
    <head>
        <meta charset="UTF-8">
        <title>MiniAid</title>
        <link rel="stylesheet" type="text/css" href="../static/styles.css">
        <link rel="icon" type="image/x-icon" href="../static/favico.png">
        <script src="../static/script.js"></script>
    </head>
    <body>
        <div class = "body-head">
            <a class = "return-button" href="/">
                <img src="../static/icons/arrow.png" class="return-icon">
                <h4>
                    Return
                </h4>
            </a>
            <div class = "body-text">
                <span class = "title">
                    MiniAid
                </span>
                <span class="subtitle">
                    About
                </span>
            </div>
            
        </div>
        
        <div class="container-about">

            <div class="section row">
                <div class="text">
                <p>The purpose of this tool is to aid miniature painters in their pre and post painting process. In the pre, upload an image of the miniature you want to paint, and select the colors
                    it will have, then use the PDF as a guide. You can also color the black-white figure (it's fun!). In the post, you can segment the miniature in the pose you want to
                    share in your social media. You also can (and this is the most fun part), take images from multiple angles and use them to 3D reconstruct the mini you painted!
                </p>
                </div>
                <div class="image-about">
                    <img src="../static/images/main.png">
                </div>
            </div>

            <hr>

            <div class="section row reverse">
                <div class="image-about">
                    <img src="../static/images/python.svg">
                </div>
                <div class="text">
                    <p>This tool was mainly built using Python language through Flask framework.
                        Python is a high-level, general-purpose programming language known for its simplicity, readability, and versatility.
                        Python emphasizes clean and easy-to-understand code, making it ideal for both beginners and experienced developers.
                        One of Python's greatest strengths is its wide range of applications;
                        it is used in web development, data science, machine learning, automation, scientific computing, game development, and much more.
                    </p>
                </div>
            </div>

            <hr>

            <div class="section row">
                <div class="text">
                    <p>To segment the images, I used Yolov11 from Ultralytics, trained on multiple miniature images on various scenarios. 
                        YOLOv11 is an advanced object detection model developed by Ultralytics, building upon the strengths of previous YOLO (You Only Look Once) versions. 
                        It is designed for real-time detection and segmentation tasks, offering improved accuracy, speed, and efficiency. 
                        YOLOv11 introduces architectural enhancements, better training strategies, and optimized performance for a wide range of scenarios, including small object detection and challenging lighting conditions.
                        Its versatility and ease of use make it popular for applications in computer vision, such as image segmentation, autonomous systems, and industrial automation.
                    </p>
                </div>
                <div class="image-about">
                    <img src="../static/images/ultralytics.svg">
                </div>
            </div>

            <hr>

            <div class="section row reverse">
                <div class="image-about">
                    <img src="../static/images/Meta AI.png">
                </div>
                <div class="text">
                    <p>
                        I used VGGT for 3D reconstruction, which is a state-of-the-art model developed by Meta AI.
                        VGGT is a feed-forward neural network that directly infers all key 3D attributes of a scene—including camera parameters, point maps, depth maps, and 3D point tracks—from one or more views.
                        This approach advances 3D computer vision by unifying tasks that were previously handled by specialized models. VGGT is simple, efficient (reconstructing images in under one second), and outperforms alternatives even without post-processing.
                        It achieves state-of-the-art results in camera parameter estimation, multi-view depth estimation, dense point cloud reconstruction, and point tracking. Pretrained VGGT also improves downstream tasks like non-rigid point tracking and novel view synthesis.
                        VGGT patchifies input images into tokens using DINO and appends camera tokens for prediction. It alternates between frame-wise and global self-attention layers.
                        A camera head predicts camera extrinsics and intrinsics, while a DPT head produces dense outputs such as depth maps, point maps, or feature maps for tracking.
                    </p>
                </div>
            </div>

        </div>

    </body>
    <footer>
        <div class = "footer">
            <a href="https://github.com/GustavoSantiago113/MiniAid" target = "_blank" class="footer-icon-link">
                <img src="../static/icons/github.png" class="footer-icon">
            </a>
            <span class = "footer-text">
                Developed by: Gustavo N. Santiago <br> Under the Creative Common NonCommercial License
            </span>
            <a href="https://gustavosantiago.shinyapps.io/WebResume/" target = "_blank" class="footer-icon-link">
                <img src="../static/icons/webResume.png" class="footer-icon">
            </a>
        </div>
    </footer>
</html>